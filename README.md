# VisionCursor

A privacy-focused Windows desktop application that uses webcam-based gaze tracking to control your mouse cursor.

## ğŸ”’ Privacy & Security First

**VisionCursor is designed with your privacy in mind:**

- âœ… **All processing happens locally** - No data ever leaves your computer
- âœ… **No video recording** - Frames are processed in-memory only
- âœ… **No telemetry** - Zero network communication
- âœ… **Minimal data storage** - Only calibration parameters (numeric values) are saved
- âœ… **No biometric templates** - We don't store facial recognition data
- âœ… **Easy data deletion** - One-click calibration data removal in the UI
- âœ… **Open source** - Full transparency, audit the code yourself

### What Data is Processed?
- **Webcam frames** - Processed in real-time, never saved to disk
- **Face landmarks** - Computed on-the-fly using MediaPipe, discarded immediately
- **Gaze vectors** - Mathematical coordinates derived from eye positions

### What Data is Stored?
- **Calibration parameters only** - A local JSON file (`calibration_data.json`) containing:
  - Screen resolution at time of calibration
  - 5 calibration target positions (screen coordinates)
  - 5 corresponding gaze feature vectors (numeric arrays)
  - Timestamp of calibration
  - **No images, no video, no biometric identifiers**

### What is NEVER Stored?
- âŒ Webcam images or video
- âŒ Facial recognition templates
- âŒ Personal identifiable information
- âŒ Usage telemetry or analytics

## Features

- ğŸ¯ **Gaze-based cursor control** - Move your mouse cursor by looking at different areas of the screen
- ğŸ¨ **Guided calibration** - Face ID-style setup with 5 calibration points
- ğŸ”§ **Adjustable sensitivity** - Fine-tune cursor speed and smoothing
- ğŸ›¡ï¸ **Safety controls** - Dead zones, velocity limiting, and emergency stop
- ğŸ­ **Debug overlay** - Visual feedback for development and troubleshooting
- â¸ï¸ **Pause/Resume** - Quick toggle to disable tracking temporarily

## System Requirements

- **OS**: Windows 10 or Windows 11
- **Python**: 3.10 or higher
- **Webcam**: Any USB or built-in webcam (720p or better recommended)
- **RAM**: 4GB minimum (8GB recommended)
- **CPU**: Modern multi-core processor (2015 or newer)

## Installation

### 1. Clone the Repository
```bash
git clone https://github.com/yourusername/visioncursor.git
cd visioncursor
```

### 2. Create Virtual Environment
```bash
python -m venv venv
venv\Scripts\activate
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Run the Application
```bash
python -m src.main
```

## Quick Start Guide

### First Time Setup

1. **Launch the application**
   ```bash
   python -m src.main
   ```

2. **Allow camera access** - Windows will prompt for camera permission

3. **Run calibration**
   - Click "Calibrate" button
   - Follow on-screen instructions
   - Look at each target dot when it appears (5 targets total)
   - Keep your head relatively still during calibration

4. **Start tracking**
   - Click "Start Tracking" button
   - Move your eyes to control the cursor
   - Adjust sensitivity slider as needed

5. **Pause/Stop**
   - Click "Pause" to temporarily disable tracking
   - Click "Stop" to end the session and release the camera

### Tips for Best Results

- ğŸª‘ **Consistent seating position** - Sit at similar distance from screen during calibration and use
- ğŸ’¡ **Good lighting** - Ensure your face is well-lit (avoid backlighting)
- ğŸ‘“ **Glasses OK** - Works with most eyeglasses (avoid heavily tinted lenses)
- ğŸ“ **Screen angle** - Keep screen perpendicular to your gaze
- ğŸ”„ **Re-calibrate** - Run calibration again if you change seating position or lighting

## Architecture

VisionCursor uses a modular architecture with clear separation of concerns:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PyQt6 GUI â”‚  (UI Layer - app_window.py, widgets.py)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Controller       â”‚  (State Machine - controller.py)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â–º Camera (camera.py)
       â”‚
       â”œâ”€â–º FaceTracker (face_tracker.py) â”€â–º MediaPipe Face Mesh
       â”‚
       â”œâ”€â–º GazeEstimator (gaze_estimator.py)
       â”‚
       â”œâ”€â–º Calibrator (calibrator.py) â”€â”€â–º CalibrationStore (storage/)
       â”‚
       â”œâ”€â–º Smoother (smoothing.py)
       â”‚
       â””â”€â–º CursorController (cursor_controller.py) â”€â–º pynput
```

See [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md) for detailed architecture documentation.

## Security & Threat Model

See [docs/THREAT_MODEL.md](docs/THREAT_MODEL.md) for:
- Threat analysis
- Attack surface
- Mitigation strategies
- Privacy guarantees

## Development

### Project Structure
```
visioncursor/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                 # Entry point
â”‚   â”œâ”€â”€ gui/                    # PyQt6 UI components
â”‚   â”œâ”€â”€ core/                   # Controller, state, config
â”‚   â”œâ”€â”€ vision/                 # Camera, face tracking, gaze estimation
â”‚   â”œâ”€â”€ os_control/             # Cursor control
â”‚   â”œâ”€â”€ storage/                # Calibration data persistence
â”‚   â””â”€â”€ utils/                  # Logging, timing utilities
â”œâ”€â”€ tests/                      # Unit tests
â”œâ”€â”€ docs/                       # Documentation
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

### Running Tests
```bash
python -m pytest tests/
```

### Debug Mode
Set environment variable to enable debug logging:
```bash
set VISIONCURSOR_LOG_LEVEL=DEBUG
python -m src.main
```

## Troubleshooting

### Camera Not Detected
- Ensure no other application is using the webcam
- Check Windows Privacy Settings â†’ Camera â†’ Allow desktop apps
- Try disconnecting/reconnecting USB webcam

### Poor Tracking Accuracy
- Run calibration again
- Improve lighting conditions
- Clean webcam lens
- Reduce sensitivity in UI
- Ensure face is centered in camera view

### High CPU Usage
- Reduce camera resolution in config
- Close other resource-intensive applications
- Update graphics drivers

### Cursor Jittery/Unstable
- Increase smoothing in UI
- Enable larger dead zone
- Reduce sensitivity
- Improve lighting for better face detection

## Known Limitations

- **Head movement** - Works best with minimal head movement; primarily tracks eye/gaze direction
- **Multiple monitors** - Currently optimized for primary monitor
- **Precision** - Not suitable for pixel-perfect tasks; best for general navigation
- **Calibration persistence** - Re-calibration needed if seating position changes significantly

## Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Add tests for new functionality
4. Ensure all tests pass
5. Submit a pull request

## License

MIT License - See LICENSE file for details

## Disclaimer

VisionCursor is experimental assistive technology. Not recommended for:
- Security-critical operations
- Tasks requiring high precision
- Replacement for accessibility features in critical applications

Always have a fallback input method available.

## Support

- ğŸ“– Documentation: [docs/](docs/)
- ğŸ› Issues: [GitHub Issues](https://github.com/yourusername/visioncursor/issues)
- ğŸ’¬ Discussions: [GitHub Discussions](https://github.com/yourusername/visioncursor/discussions)

---

**Built with privacy, security, and user control as core principles.**
